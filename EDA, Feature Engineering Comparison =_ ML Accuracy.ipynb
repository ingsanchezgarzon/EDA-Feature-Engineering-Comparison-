{"cells":[{"metadata":{"_uuid":"83f93130-31bb-403f-a0c4-d922db5cf1d2","_cell_guid":"43750dae-6b7c-49a3-aed9-af8b20910e6e","trusted":true},"cell_type":"markdown","source":"<h1> Welcome to my Titanic Kernel! </h1>"},{"metadata":{"_uuid":"563b0e05-ac23-4fa9-b667-7da64922999d","_cell_guid":"cb29efa7-0d31-409f-a95f-ae25182097f6","trusted":true},"cell_type":"markdown","source":"Here you find basic Data Exploration and Visualization, data handling with some features, and modelling.\n\n**This Kernel Focus on the effects of some features in the performance of the learning algorithms** \n\n\nI used most the common supervise learning classification algorithms. \nI compared them in a train/test set and I chose some for submiting the answers"},{"metadata":{"_uuid":"26ae1732-d44b-4fb9-8532-920170bfc1bf","_cell_guid":"c238ab20-53f5-49f3-85c7-53645a74db2e","trusted":true},"cell_type":"markdown","source":" Table of Contents:\n \n **1. [Introduction & Imports](#Introduction)** <br>\n **2. [Exploratory Data Analysis](#EDA)** <br>\n **3. [Feature Engineering](#Feature)** <br>\n **4. [Preparing the Test dataframe](#test)** <br>\n **5. [Testing several Supervise learning models](#ML)** <br>\n **6. [Trainning all data on some Classifiers](#train)** <br>\n **7. [Results](#results)** <br>\n"},{"metadata":{"_uuid":"7fcca76b-fb10-4b0f-a8c7-18343170c22a","_cell_guid":"96b1f561-24a2-42cd-bf0a-b715d24868a7","trusted":true},"cell_type":"markdown","source":"<a id=\"Introduction\"></a> <br> \n **1. Introduction & Imports** \n"},{"metadata":{"_uuid":"33e5b603-6104-4856-adef-71524898c877","_cell_guid":"1f5173d8-1598-48a1-8820-db904f304925","trusted":true},"cell_type":"markdown","source":"Import some libraries for data exploration"},{"metadata":{"_uuid":"181b8af5-e1b6-4397-8a72-3fcd959dd2fa","_cell_guid":"900ab863-6e1b-4b3b-a3fd-591292e38320","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\n\nimport os\n#print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15c1e434-e898-4caa-8b15-86f0f212d952","_cell_guid":"5e8809e6-16c8-4568-9de8-ef29d22fc223","trusted":true},"cell_type":"markdown","source":"**Import Data & Exploratory Data Analysis**"},{"metadata":{"_uuid":"6a19a438-cd00-44d4-aeae-32684f96c985","_cell_guid":"ea74dfe1-146f-400b-b0ac-75891224850b","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\n#drop cabin, Name and Ticket data that are not neccesary to train the model\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"940cd5aa-9101-4d3c-88a7-5f0fa0e21a41","_cell_guid":"e406911e-5c42-48c7-8943-318514c14999","trusted":true},"cell_type":"markdown","source":"<a id=\"EDA\"></a> <br> \n **2. Exploratory Data Analysis**"},{"metadata":{"_uuid":"d5e6a343-de34-4105-840c-1f161c99f0cf","_cell_guid":"e2e11d64-425a-450f-b986-26893924d76a","trusted":true},"cell_type":"markdown","source":"The first step is the detect in which columns there are non valid values"},{"metadata":{"_uuid":"4912d78a-9822-459f-952f-1f04847354f9","_cell_guid":"fa9cc8d4-8798-406b-92ad-c11b634c2b59","trusted":true},"cell_type":"code","source":"#Check for the missing values in the columns \nfig, ax = plt.subplots(figsize=(9,5))\nsns.heatmap(train.isnull(), cbar=False, cmap=\"YlGnBu_r\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Supposing that the categorical values such as the Name, the Cabin, the Ticket code and the ID doesnt have any relationship to the fact that the passanger died or survived:"},{"metadata":{"_uuid":"5fdb4253-b942-4ac1-8951-2fd28c1d8521","_cell_guid":"c476789c-73a8-40d2-934c-97aac83cc5d1","trusted":true},"cell_type":"code","source":"#I drop those columns\ntrain = train.drop(columns = ['Cabin','Name','Ticket','PassengerId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling Non valid values with mean for age, \ntrain['Age'].fillna((train['Age'].mean()), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea442dcc-488c-4982-98c4-32cea33b8c37","_cell_guid":"f26c646a-af1f-43cd-bb59-3b947955ebfd","trusted":true},"cell_type":"markdown","source":"**Survival as function of Pclass and Sex**\n"},{"metadata":{"_uuid":"a41c0a6c-1ecb-4930-b445-aca10a51d711","_cell_guid":"276344a8-311a-4992-a1ca-3e35107b227f","trusted":true},"cell_type":"markdown","source":"To start the exploration, it is possible to group passanger by Sex and Class, these groups could give insights if higher class have better chance of survive, or woman have better chance than men for example."},{"metadata":{"_uuid":"9ded0289-4f2d-4a79-8df1-405be5211732","_cell_guid":"8f8eeb93-1072-4e66-9d83-b43bf47eb746","trusted":true},"cell_type":"code","source":"sns.barplot(x='Sex', y='Survived', data=train)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival as function of Sex\", fontsize=16)\n\nplt.show()\ntrain[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This information can be displayed in the next plot too:\n#sns.catplot(x='Sex', col='Survived', kind='count', data=train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"484ba4fd-0744-4106-b987-dcaf2198e587","_cell_guid":"17ff5621-f7ec-44eb-9139-1a7fa6698c39","trusted":true},"cell_type":"markdown","source":"It is clear that women have better chance than men. \nIf you create a model saying that only woman survive it would have a score of **0.76555**, so the mission is to create a model at least better\n\nNext, I explore the change of survive regardign the passanger Class:"},{"metadata":{"_uuid":"607f09f2-04bb-4f03-9cd6-b5b228dcf53f","_cell_guid":"003f1ba7-ece6-4305-8043-876ebdf8e5d2","trusted":true},"cell_type":"code","source":"sns.barplot(x='Pclass', y='Survived', data=train)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival as function of Pclass\", fontsize=16)\n\nplt.show()\ntrain[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b01d45db-203d-4ffe-b7a0-c4d7a5e5f945","_cell_guid":"6f28ead0-8731-4458-a00b-ab82719d6b67","trusted":true},"cell_type":"markdown","source":" I explore both PClass and Sex in the same plot:"},{"metadata":{"_uuid":"061aeddc-05c4-45e6-9713-0baa6951b31b","_cell_guid":"4f656216-4338-46d2-aeb4-2b8572156317","trusted":true},"cell_type":"code","source":"sns.barplot(x='Sex', y='Survived', hue='Pclass', data=train)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival as function of Pclass and Sex\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, Explore the Parch and SibSp column:"},{"metadata":{"_uuid":"74a16ce9-03ec-488e-8d88-7bab8fde5319","_cell_guid":"2a4461d2-3df8-4b32-a22c-017a6a9e1dec","trusted":true},"cell_type":"code","source":"train[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02bf6b0a-64ff-4158-924c-9643b19d9d8e","_cell_guid":"58e61842-af6a-44e0-ac0f-e2a15e05d8ed","trusted":true},"cell_type":"code","source":"train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7f1bdd7-a1d0-47ee-9782-4e2c2e41e479","_cell_guid":"e85d8bf1-b53d-4e32-b376-a5ea12b839a7","trusted":true},"cell_type":"markdown","source":"To get a better insight of the relationship of these features and the survival rate, a general pairplot will give some clues:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=train, hue=\"Survived\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Feature\"></a> <br> \n **3. Feature Engineering**"},{"metadata":{},"cell_type":"markdown","source":"The features can be built to:\n- reduce the number of states of the SibSp and Parch column\n- Create smaller classes for continues columns, such as Age and Fare\n- Create new columns that could improve prediction: such as if the passanger is alone or not\n- Drop columns that doesn't improve predictions"},{"metadata":{},"cell_type":"markdown","source":"The first features to work on are SibSp and Parch"},{"metadata":{"trusted":true},"cell_type":"code","source":"# I Create a swarmplot to detect patterns, where is the highest survival rate? \nsns.swarmplot(x = 'SibSp', y = 'Parch', hue = 'Survived', data = train, split = True, alpha=0.8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To explore better the relationship between these variables before featuring, I create a first model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nfrom pdpbox import pdp, get_dataset, info_plots\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nyf = train.Survived\nbase_features = ['Parch',\n                 'SibSp','Age', 'Fare','Pclass']\n\nXf = train[base_features]\n\ntrain_X, val_X, train_y, val_y = train_test_split(Xf, yf, random_state=1)\nfirst_model = RandomForestRegressor(n_estimators=21, random_state=1).fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Explore the relationship between SipSp and Parch in the predictions for a RF Model\ninter  =  pdp.pdp_interact(model=first_model, dataset=val_X, model_features=base_features, features=['SibSp', 'Parch'])\n\npdp.pdp_interact_plot(pdp_interact_out=inter, feature_names=['SibSp', 'Parch'], plot_type='contour')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, introducing new features as Family size (to join these Parch and SibSp)"},{"metadata":{"_uuid":"e4f1e79e-2c30-4bdf-88e9-0d38a27e00f0","_cell_guid":"c304bf75-74a7-4dc5-8204-dc415cad7a15","trusted":true},"cell_type":"code","source":"train['FamilySize'] = train['SibSp'] + train['Parch'] \ntrain[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).agg('mean')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next option is to cerate IsAlone feature to check wheter a person traveling alolne is more likely to survived or died"},{"metadata":{"_uuid":"56bee1a7-c407-446b-8dd7-18ef913a73cf","_cell_guid":"43ed8860-3ba5-4e6e-9bae-7de0b4d0deb9","trusted":true},"cell_type":"code","source":"train['IsAlone'] = 0\ntrain.loc[train['FamilySize'] == 0, 'IsAlone'] = 1\n\ntrain[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05ef67e0-88c2-4386-8325-be70d7e3a557","_cell_guid":"c62d7ed6-c854-4511-9c23-8a1c7752b130","trusted":true},"cell_type":"markdown","source":"To sum up the work, the next set of graphics shows the relationships with and without the new features"},{"metadata":{"_uuid":"1a3e2571-fde1-4313-9ba2-7be8ae37e2f4","_cell_guid":"3d2092ef-28ce-46c0-abdd-e3795bfae232","trusted":true},"cell_type":"code","source":"cols = ['Survived', 'Parch', 'SibSp', 'Embarked','IsAlone', 'FamilySize']\n\nnr_rows = 2\nnr_cols = 3\n\nfig, axs = plt.subplots(nr_rows, nr_cols, figsize=(nr_cols*3.5,nr_rows*3))\n\nfor r in range(0,nr_rows):\n    for c in range(0,nr_cols):  \n        \n        i = r*nr_cols+c       \n        ax = axs[r][c]\n        sns.countplot(train[cols[i]], hue=train[\"Survived\"], ax=ax)\n        ax.set_title(cols[i], fontsize=14, fontweight='bold')\n        ax.legend(title=\"survived\", loc='upper center') \n        \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb8ed6bf-3fd2-48b0-a133-4cb8579c4ae1","_cell_guid":"da99bd1a-cd7c-401a-b938-029363ff5428","trusted":true},"cell_type":"markdown","source":"**The Fare Column**"},{"metadata":{},"cell_type":"markdown","source":"This continus feature could be converted in a continues feature in order to increase prediction of the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_name = 'Fare'\npdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The fare is distributed in several continues values, and it is not clear how can we discretize these values to improve model's performance."},{"metadata":{"_uuid":"a7e25966-5cf4-45d6-92f8-505f14bfffd7","_cell_guid":"45809cb8-b25f-4dba-abd6-842c52d67d71","trusted":true},"cell_type":"markdown","source":"To solve this problem, first, it would be likely to think that the chance of survival could depend on the Fare"},{"metadata":{"_uuid":"9ae28a2f-0bd4-4a23-8f8f-b24925e77975","_cell_guid":"7c0ba346-be4b-4e91-83f9-47f65e45a0ca","trusted":true},"cell_type":"code","source":"train[[\"Fare\", \"Survived\"]].groupby(['Survived'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Highest fare mean improve the chance of survival\nWe know that female have better chance than male, so we group the data in these values:"},{"metadata":{"_uuid":"86130e38-cc55-4fb1-879f-578e5a271d8f","_cell_guid":"2e9e086f-129d-4b33-ac1b-340126d0298e","trusted":true},"cell_type":"code","source":"train.groupby(['Sex','Survived'])[['Fare']].agg(['min','mean','max'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff2ba12d-c01b-4403-bad8-29d556bc3d81","_cell_guid":"f00587a7-c239-40f5-9619-6c15d42c56bf","trusted":true},"cell_type":"markdown","source":"Based on the exploration of the data, I propose to discretize the Fare in four states:"},{"metadata":{"_uuid":"f502506c-ca2f-41fe-a3be-7b6d202ab035","_cell_guid":"d6aad408-437d-4cec-8efa-c4aba19ed24d","trusted":true},"cell_type":"code","source":"train.loc[ train['Fare'] <= 7.22, 'Fare'] = 0\ntrain.loc[(train['Fare'] > 7.22) & (train['Fare'] <= 21.96), 'Fare'] = 1\ntrain.loc[(train['Fare'] > 21.96) & (train['Fare'] <= 40.82), 'Fare'] = 2\ntrain.loc[ train['Fare'] > 40.82, 'Fare'] = 3\ntrain['Fare'] = train['Fare'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2b75247-de1d-4928-8820-96ebbf142fda","_cell_guid":"e3a40c38-1964-4b79-afac-87b6a7d37d2f","trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(train, col='Survived')\ng.map(plt.hist, 'Fare', bins=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c00abcc-a2be-482f-a851-8750ef416a44","_cell_guid":"4dfe9c0e-7818-471f-8ff4-e0dd747cbaea","trusted":true},"cell_type":"code","source":"sns.barplot(x='Sex', y='Survived', hue='Fare', data=train)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival as function of Fare and Sex\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This plot show us how the new fare states are relatid to Sex and rate of survival. Higher fare have better chance of survive than lower fare, and female more than male in general."},{"metadata":{"_uuid":"702c5e69-49c1-4a66-99f7-da1a74091fb3","_cell_guid":"cb997a5e-ddc8-4d19-9152-b4e406d3c3a8","trusted":true},"cell_type":"markdown","source":"**Now the relationship between age and survived**"},{"metadata":{},"cell_type":"markdown","source":"Age has continue values too:"},{"metadata":{"_uuid":"a53e4e64-b3e5-4424-92a5-fd5ac45ef0f1","_cell_guid":"dbcf2b60-68b7-4b29-abcf-54af092d8f12","trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(train, col='Survived')\ng.map(plt.hist, 'Age', bins=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I check in a first model how can age correlate with the chance of survive, also related to the passanger Class:"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_name = 'Age'\npdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()\n#Exploring the relationship between Age and Pclass for a given model preductions\ninter  =  pdp.pdp_interact(model=first_model, dataset=val_X, model_features=base_features, features=['Age', 'Pclass'])\n\npdp.pdp_interact_plot(pdp_interact_out=inter, feature_names=['Age', 'Pclass'], plot_type='contour')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems like less age and higher class is a better combination to survive. "},{"metadata":{"_uuid":"679c2964-d6ef-41ca-9a1f-e06c36df7cfa","_cell_guid":"31a0cf4e-feee-4436-b4e6-0fe58af27e0e","trusted":true},"cell_type":"code","source":"#bins=np.arange(0, 80, 10)\ng = sns.FacetGrid(train, row='Sex', col='Pclass', hue='Survived', margin_titles=True, size=3, aspect=1.1)\ng.map(sns.distplot, 'Age', kde=False, bins=4, hist_kws=dict(alpha=0.6))\ng.add_legend()  \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a568c27-3550-4afe-8285-0967d1461c25","_cell_guid":"ffce0f0a-f1a1-4cac-b8d8-2e94fb18a57d","trusted":true},"cell_type":"markdown","source":"Following the graphics below, The age can be groupped into less classes:"},{"metadata":{"_uuid":"56ada344-3059-43bf-af13-d49d63d29496","_cell_guid":"f265d0b6-d143-4262-a020-f73a0fec4fe3","trusted":true},"cell_type":"code","source":"train.loc[ train['Age'] <= 16, 'Age'] = 1\ntrain.loc[(train['Age'] > 16) & (train['Age'] <= 32), 'Age'] = 2\ntrain.loc[(train['Age'] > 32) & (train['Age'] <= 64), 'Age'] = 3\ntrain.loc[ train['Age'] > 64, 'Age'] = 4\ntrain['Age'] = train['Age'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de31446a-5776-4535-8844-8fac86289582","_cell_guid":"a5978957-713f-47fe-997e-c5e615d076d3","trusted":true},"cell_type":"code","source":"sns.barplot(x='Pclass', y='Survived', hue='Age', data=train)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival as function of Age and Sex\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This plot show us how higher class and lower age have better chance of survive, while lower class (3) and older (age >2) have lower chance of survive.\nThis seems logic, the reduction of classes can improve the learning of the model based on the (relative small) data we have  "},{"metadata":{},"cell_type":"markdown","source":"finally I explore new features, for example, a measure of 'Age x Class' would give better insight of the survival rate? "},{"metadata":{"_uuid":"a943c999-985a-4c68-b760-0b378fca457f","_cell_guid":"6c453d8a-a385-4161-82a2-77b4d2f529bf","trusted":true},"cell_type":"code","source":"train['Age*Class'] = train.Age * train.Pclass","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"112a1dc2-de58-46a5-bac1-f90fee189ca8","_cell_guid":"6dd35f22-fdc7-4a96-93ef-20e9feaa7835","trusted":true},"cell_type":"code","source":"train[[\"Age*Class\", \"Survived\"]].groupby(['Age*Class'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Less values give a clue of more survival mean, however a crosstab maybe would give more clear information:"},{"metadata":{"_uuid":"b7467c5a-2eac-4e39-9997-2605213627bc","_cell_guid":"a8fc7ac9-96e0-44d2-ad95-47e2cfa85d71","trusted":true},"cell_type":"code","source":"pd.crosstab([train.Survived], [train.Sex,train['Age*Class']], margins=True).style.background_gradient(cmap='autumn_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the new featre show how female in AgexClass between 2 to 6 have better chance of survive, and male from 4 to 6 AgexClass have lower chance of survive "},{"metadata":{},"cell_type":"markdown","source":"The same analysis for the IsAlone feature:"},{"metadata":{"_uuid":"e99cfaa3-566e-4c3a-8bb2-09bd722f4f77","_cell_guid":"32fd9265-b21b-4bf5-94c0-bb1b0438cc38","trusted":true},"cell_type":"code","source":"pd.crosstab([train.Survived], [train.Sex,train['IsAlone']], margins=True).style.background_gradient(cmap='autumn_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"men who were alone have lower chance of survive"},{"metadata":{"_uuid":"54b1cda6-500a-49c3-9f5d-fef42c2251ff","_cell_guid":"ee901d2e-8f06-4cae-b817-8b150373089c","trusted":true},"cell_type":"code","source":"pd.crosstab([train.Survived], [train.Fare], margins=True).style.background_gradient(cmap='autumn_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This last crosstab show how the people having Fare group 1 (Fare > 7.22 & Fare <= 21.96) have the lower chance of survive, \n\nThe presented groupes show the tendency of the data. However is hard to know wheter these groups really optimize the larning. This work only can be done by trial and error"},{"metadata":{},"cell_type":"markdown","source":"**Estimation of the Survival rate using the new features defined **"},{"metadata":{},"cell_type":"markdown","source":"this is how the new train dataframe looks like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, I would simulate the training using the new features "},{"metadata":{"trusted":true},"cell_type":"code","source":"y2 = train.Survived\n\nbase_features2 = ['Parch','SibSp','Age', 'Fare','Pclass','Age*Class','FamilySize','IsAlone']\n\nX2 = train[base_features2]\ntrain_X2, val_X2, train_y2, val_y2 = train_test_split(X2, y2, random_state=1)\nsecond_model = RandomForestRegressor(n_estimators=21, random_state=1).fit(train_X2, train_y2)\n\ninter2  =  pdp.pdp_interact(model=second_model, dataset=val_X2, model_features=base_features2, features=['Age', 'Pclass'])\npdp.pdp_interact_plot(pdp_interact_out=inter2, feature_names=['Age', 'Pclass'], plot_type='contour')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These new features provide a more clear distribution that the dataframe without features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_name = 'FamilySize'\npdp_dist = pdp.pdp_isolate(model=second_model, dataset=val_X2, model_features=base_features2, feature=feat_name)\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inter2  =  pdp.pdp_interact(model=second_model, dataset=val_X2, model_features=base_features2, features=['FamilySize', 'Pclass'])\npdp.pdp_interact_plot(pdp_interact_out=inter2, feature_names=['FamilySize', 'Pclass'], plot_type='contour')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also for the Passanger Class and its family size. After defining the new groups, it's more clear for the algorithm that lower class and lower family size increase the chance of survive "},{"metadata":{},"cell_type":"markdown","source":"Now I explore the effects of the other featuers independently"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_name = 'IsAlone'\npdp_dist = pdp.pdp_isolate(model=second_model, dataset=val_X2, model_features=base_features2, feature=feat_name)\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_name = 'Age*Class'\npdp_dist = pdp.pdp_isolate(model=second_model, dataset=val_X2, model_features=base_features2, feature=feat_name)\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For Is alone and AgexClass, the effect in the survival rate is not that clear"},{"metadata":{"trusted":true},"cell_type":"code","source":"inter2  =  pdp.pdp_interact(model=second_model, dataset=val_X2, model_features=base_features2, features=['Age*Class', 'IsAlone'])\npdp.pdp_interact_plot(pdp_interact_out=inter2, feature_names=['Age*Class', 'IsAlone'], plot_type='contour')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As Sex and Embarked are not numerical I do the pandas OneHotEncoder:"},{"metadata":{"_uuid":"f1eb1092-9ae1-4d2c-bb6b-ec13bb8cba49","_cell_guid":"884f0f9a-c6eb-48ab-b063-762ee483f51b","trusted":true},"cell_type":"code","source":"# convert Sex values and Embearked values into dummis to use a numerical classifier \ndummies_Sex = pd.get_dummies(train.Sex)\ndummies_Embarked = pd.get_dummies(train.Embarked)\n#join the dummies to the final dataframe\ntrain_ready = pd.concat([train, dummies_Sex,dummies_Embarked], axis=1)\ntrain_ready.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and drop the respective columns:"},{"metadata":{"_uuid":"5077c4be-5b08-4f96-aa01-ab83ac808037","_cell_guid":"97dc6b7a-9e0f-427a-ba6f-f503a06c9f22","trusted":true},"cell_type":"code","source":"#Drop the columns that are not usefull now\n#train_ready = train_ready.drop(columns = ['Sex','Embarked','male','SibSp','Parch','Q'])\n\ntrain_ready = train_ready.drop(columns = ['Sex','Embarked'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the AgexClass can be dropped or not as I experiment to increase the general performance of the model in the next steps:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_ready = train_ready.drop(columns = ['Age*Class'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"same for the FamiliSize columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_ready = train_ready.drop(columns = ['FamilySize'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f55a18c0-2a76-4c78-a6b6-366c375a8c89","_cell_guid":"bb9db292-6bd1-4c79-b93a-edb6f5913647","trusted":true},"cell_type":"code","source":"#alst check before trainning\ntrain_ready.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef87697b-fb29-47c4-be0f-b7203ee0314b","_cell_guid":"ecaf9c4a-3923-43c5-b861-f62df3d6ed1b","trusted":true},"cell_type":"code","source":"train_ready.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ac946bd-c74a-47a3-b0eb-dab4578b93de","_cell_guid":"d9700e3b-2079-4cb9-9596-fe4e18e44004","trusted":true},"cell_type":"markdown","source":"I explore the entropy to check wheter the values can give a good learning to the algoritmh"},{"metadata":{"_uuid":"0a7acc6a-2360-4e17-94ec-53ed772cde35","_cell_guid":"0e360d73-4b40-44b8-8602-5f59490cdd56","trusted":true},"cell_type":"code","source":"from scipy import stats\nfor name in train_ready:\n    print(name, \"column entropy :\", round(stats.entropy(train_ready[name].value_counts(normalize=True), base=2),2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I train the model, then I came back and drop AgexClass Siwe column (entropy 2,14) then I train again the model droping the FamilySize column (entropy 1,82)"},{"metadata":{"_uuid":"ebcf3544-cb1d-4409-9b10-c9ba7cab9013","_cell_guid":"3be8bafa-4eca-45b1-aac2-8eb5cbb7b6df","trusted":true},"cell_type":"markdown","source":"<a id=\"test\"></a> <br> \n**4. Preparing the Test dataframe**"},{"metadata":{"_uuid":"a5db4b2c-4610-4579-922b-0284a9281fe6","_cell_guid":"c1792a6a-1d42-4a2e-a817-17b435fe6b51","trusted":true},"cell_type":"raw","source":"Here I complete the same steps for the test set"},{"metadata":{"_uuid":"e5326306-5890-4320-b190-7e823c1a7317","_cell_guid":"cd061394-a686-436f-b5c4-f471f44c67f7","trusted":true},"cell_type":"code","source":"#Upload the test file \ntest = pd.read_csv(\"../input/test.csv\")\n\n#Drop unecessary columns\ntest = test.drop(columns = ['Cabin','Name','Ticket','PassengerId'])\n#check the test dataframe\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for the missing values in the columns \nfig, ax = plt.subplots(figsize=(9,5))\nsns.heatmap(test.isnull(), cbar=False, cmap=\"YlGnBu_r\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling Non valid values with mean for age, \ntest['Age'].fillna((test['Age'].mean()), inplace=True)\ntest['Fare'].fillna((test['Fare'].mean()), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1baaee8f-4402-4de6-88f5-8c34b8d739bd","_cell_guid":"ef4b520a-a57f-4e98-8f43-906feada4402","trusted":true},"cell_type":"code","source":"test.loc[ test['Fare'] <= 7.22, 'Fare'] = 0\ntest.loc[(test['Fare'] > 7.22) & (test['Fare'] <= 21.96), 'Fare'] = 1\ntest.loc[(test['Fare'] > 21.96) & (test['Fare'] <= 40.82), 'Fare'] = 2\ntest.loc[ test['Fare'] > 40.82, 'Fare'] = 3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c34e8bfa-04d3-4742-9d3d-2276fc5fc612","_cell_guid":"e8228444-6fdc-49ba-a203-a6490a0a4513","trusted":true},"cell_type":"code","source":"test['FamilySize'] = test['SibSp'] + test['Parch'] + 1\ntest['IsAlone'] = 0\ntest.loc[test['FamilySize'] == 1, 'IsAlone'] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1cbe1ed6-1d48-43d0-bf16-6cd887db7c67","_cell_guid":"311491c5-8584-4347-9968-0ee4f33173cd","trusted":true},"cell_type":"code","source":"test.loc[ test['Age'] <= 16, 'Age'] = 1\ntest.loc[(test['Age'] > 16) & (test['Age'] <= 32), 'Age'] = 2\ntest.loc[(test['Age'] > 32) & (test['Age'] <= 64), 'Age'] = 3\ntest.loc[ test['Age'] > 64, 'Age'] = 4","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc0a6ebf-6ca6-440c-95a9-efc838653753","_cell_guid":"1186c60d-0fd3-44ab-8a95-39d58540da02","trusted":true},"cell_type":"code","source":"test['Age*Class'] = test.Age * test.Pclass","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8662409-5c7c-4989-b6f6-3d14000fdd67","_cell_guid":"77f395ef-9556-47b1-866c-bcea9e327f14","trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82f9eec7-6eb4-4ac3-9b1f-cb533b9bdaf1","_cell_guid":"941402bd-1b90-44c2-97d2-c6eee0a64fd3","trusted":true},"cell_type":"code","source":"#as in the train dataset, build dummis in the sex and embarked columns\ntest_dummies_Sex = pd.get_dummies(test.Sex)\ntest_dummies_Embarked = pd.get_dummies(test.Embarked)\ntest_ready = pd.concat([test, test_dummies_Sex,test_dummies_Embarked], axis=1)\ntest_ready.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d7cea5e-a9a5-4a50-9fd9-51da5127ccec","_cell_guid":"96cc684c-569e-44df-b1f3-ad53cdb3c952","trusted":true},"cell_type":"code","source":"#drop these columns, we keep only numerical values\n#train_ready = train_ready.drop(columns = ['Sex','Embarked','Survived','SibSp','Parch'])\ntest_ready = test_ready.drop(columns = ['Sex','Embarked'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When dropping the colmuns in the train dataset it would be neccesary to do the same in the test dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_ready = test_ready.drop(columns = ['Age*Class'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_ready = test_ready.drop(columns = ['FamilySize'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56294fa6-35e9-4a49-a4bf-8cecd854dff9","_cell_guid":"f5535618-7930-4e8f-b38b-0905b8673009","trusted":true},"cell_type":"code","source":"#check all is ok \ntest_ready.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c1d0367-c190-4dec-b023-24f2ad04afc4","_cell_guid":"87ab7733-3588-43e7-8278-69a4e5dbff1e","trusted":true},"cell_type":"code","source":"test_ready.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"daa0b3af-af54-4ea6-a1f8-bd66dae0c2f4","_cell_guid":"ce8d3293-96aa-4501-82ed-9f5b42598d0a","trusted":true},"cell_type":"markdown","source":"I explore the entropy to check wheter the values can give a good learning to the algoritmh"},{"metadata":{"_uuid":"87f4a6ec-0f64-482a-8ea2-4d4b4006c36e","_cell_guid":"44a3ac26-c6f4-435c-9510-2c49fa7dbd61","trusted":true},"cell_type":"code","source":"from scipy import stats\nfor name in test_ready:\n    print(name, \"column entropy :\",round(stats.entropy(test_ready[name].value_counts(normalize=True), base=2),2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"379f68da-24d8-45e1-a6d6-ba201d149d76","_cell_guid":"c4f784ed-073b-4c2a-8f01-e133ebf20820","trusted":true},"cell_type":"markdown","source":"<a id=\"ML\"></a> <br> \n**5. Testing several Supervise learning models** \n"},{"metadata":{"_uuid":"b62c01c0-e114-431e-8d4b-eb4610294ae8","_cell_guid":"a71a3661-397f-4761-9e5e-25c7e331a68c","trusted":true},"cell_type":"markdown","source":"First, I would use a train/test division on the test csv, and I would check the performance of several algorithms:"},{"metadata":{"_uuid":"5661bdb3-b5ae-4a84-8939-edc9aab7e4ad","_cell_guid":"cf534fe8-bb85-4740-8397-aa0a3b3bb5f0","trusted":true},"cell_type":"code","source":"## import ML\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c19ad286-42a9-49fa-aef0-eaa101bc09b6","_cell_guid":"9c3668af-cc6d-42ce-aa99-02f89d0a2b3a","trusted":true},"cell_type":"code","source":"# Create arrays for the features and the response variable\ny = train_ready['Survived'].values\nX = train_ready.drop('Survived',axis=1).values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f940a5a-a343-4992-aa10-cdeec11cf916","_cell_guid":"475b1f38-f409-4b62-9090-ae222f924fe8","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=21, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d62c55f-e639-4b7f-92dc-dd6e03304977","_cell_guid":"019b824f-01e0-4e14-8f4c-e2d4b10a3185","trusted":true},"cell_type":"code","source":"#Importing the auxiliar and preprocessing librarys \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.metrics import accuracy_score\n\n#Models\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, RandomTreesEmbedding","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3a84acc-1de9-411e-9e8d-b6d7e7e73b3d","_cell_guid":"7bb810d4-d44e-46cb-8620-46835f9691a4","trusted":true},"cell_type":"code","source":"clfs = []\nseed = 3\n\nclfs.append((\"LogReg\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"LogReg\", LogisticRegression())])))\n\nclfs.append((\"XGBClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"XGB\", XGBClassifier())]))) \nclfs.append((\"KNN\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"KNN\", KNeighborsClassifier(n_neighbors=8))]))) \n\nclfs.append((\"DecisionTreeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"DecisionTrees\", DecisionTreeClassifier())]))) \n\nclfs.append((\"RandomForestClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RandomForest\", RandomForestClassifier())]))) \n\nclfs.append((\"GradientBoostingClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"GradientBoosting\", GradientBoostingClassifier(n_estimators=100))]))) \n\nclfs.append((\"RidgeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RidgeClassifier\", RidgeClassifier())])))\n\nclfs.append((\"BaggingRidgeClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"BaggingClassifier\", BaggingClassifier())])))\n\nclfs.append((\"ExtraTreesClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"ExtraTrees\", ExtraTreesClassifier())])))\n\n#'neg_mean_absolute_error', 'neg_mean_squared_error','r2'\nscoring = 'accuracy'\nn_folds = 7\n\nresults, names  = [], [] \n\nfor name, model  in clfs:\n    kfold = KFold(n_splits=n_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, y_train, \n                                 cv= 5, scoring=scoring,\n                                 n_jobs=-1)    \n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+/- %f)\" % (name, cv_results.mean(),  cv_results.std())\n    print(msg)\n    \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15,6))\nfig.suptitle('Classifier Algorithm Comparison', fontsize=22)\nax = fig.add_subplot(111)\nsns.boxplot(x=names, y=results)\nax.set_xticklabels(names)\nax.set_xlabel(\"Algorithmn\", fontsize=20)\nax.set_ylabel(\"Accuracy of Models\", fontsize=18)\nax.set_xticklabels(ax.get_xticklabels(),rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"896e0d6f-91b6-4713-9622-09e52ed7a8a3","_cell_guid":"8f6a9a8a-c0b9-48a3-a1f3-1ff57a4cb901","trusted":true},"cell_type":"code","source":"perm_xgb = PermutationImportance(XGBClassifier().fit(X_train, y_train), random_state=1).fit(X_test,y_test)\neli5.show_weights(perm_xgb, feature_names = train_ready.drop('Survived',axis=1).columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a227276-ba8a-445e-a25d-36db19ef855f","_cell_guid":"98ed5d21-64b8-481e-a951-4d799066445e","trusted":true},"cell_type":"code","source":"perm_knn = PermutationImportance(KNeighborsClassifier(n_neighbors=8).fit(X_train, y_train), random_state=1).fit(X_test,y_test)\neli5.show_weights(perm_knn, feature_names = train_ready.drop('Survived',axis=1).columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e33dba33-1078-41a3-b3b1-f99743a44470","_cell_guid":"9661a954-4cfd-48ab-9cdc-9b933b3e7ca6","trusted":true},"cell_type":"code","source":"perm_gbc = PermutationImportance(GradientBoostingClassifier(n_estimators=100).fit(X_train, y_train), random_state=1).fit(X_test,y_test)\neli5.show_weights(perm_gbc, feature_names = train_ready.drop('Survived',axis=1).columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f3d52b7-7665-4cf8-b7e7-ff25a0ec7deb","_cell_guid":"850b1d2e-a737-4a4c-a929-e6d70dc58223","trusted":true},"cell_type":"code","source":"perm_gbc = PermutationImportance(RidgeClassifier().fit(X_train, y_train), random_state=1).fit(X_test,y_test)\neli5.show_weights(perm_gbc, feature_names = train_ready.drop('Survived',axis=1).columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_ready.drop('Survived',axis=1).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ready.drop('Survived',axis=1).info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ready.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Here I can drop the columns as AgexClass and IsAlone to check wheter the algorithms produce better performance ***"},{"metadata":{"_uuid":"ad3e2c3a-5b96-4998-bbd8-65b5358ea6b4","_cell_guid":"f3781c9a-b795-477e-a02a-0c7355f0cdf2","trusted":true},"cell_type":"markdown","source":"**Bulding the model for the test set **"},{"metadata":{"_uuid":"1a3b3c9e-0ca6-404d-8d30-95e4d3d6a6ab","_cell_guid":"67f4148c-f804-4f8f-aaac-8ee513a7e75b","trusted":true},"cell_type":"code","source":"#apply Scla to train in order to standardize data \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nscaler.fit(X)\nscaled_features = scaler.transform(X)\ntrain_sc = pd.DataFrame(scaled_features) # columns=df_train_ml.columns[1::])\n\n#apply Scla to test csv (new file)  in order to standardize data \n\nX_csv_test = test_ready.values  #X_csv_test the new data that is going to be test \nscaler.fit(X_csv_test)\nscaled_features_test = scaler.transform(X_csv_test)\ntest_sc = pd.DataFrame(scaled_features_test) # , columns=df_test_ml.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"178ffbd2-d33d-44f4-a871-c5df70aaf8f5","_cell_guid":"f22956d2-e5c3-42dd-8e58-e479f9acad2d","trusted":true},"cell_type":"code","source":"scaled_features_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6812d37c-9131-42ea-badd-1f9e5efd10ed","_cell_guid":"f8bee674-79dc-4d99-8e4b-d02beb879152","trusted":true},"cell_type":"code","source":"scaled_features.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ed16625-4b13-4ad9-a960-fea75f7d557f","_cell_guid":"f2baadcf-34b9-4247-9706-fdd7ec6d3f81","trusted":true},"cell_type":"markdown","source":"<a id=\"train\"></a> <br> \n**6. Trainning all data on several Classifier**"},{"metadata":{"_uuid":"fa5cc3bb-c611-4580-8755-a1c3df635539","_cell_guid":"0120a604-0341-4c94-ab00-375fac5cc419","trusted":true},"cell_type":"markdown","source":"**First Model: KNN**"},{"metadata":{"_uuid":"7c081297-1fc3-44f3-a87e-036755c7279c","_cell_guid":"dccc0149-2254-4569-b576-6a750fbf4af4","trusted":true},"cell_type":"markdown","source":"First we run this loop to detect the correct number of Nieghbors in KNN"},{"metadata":{"_uuid":"f38780c5-5d77-44c8-9ccd-c32424674610","_cell_guid":"9045539d-1736-4db0-8659-d8f8cc549e15","trusted":true},"cell_type":"code","source":"# Import KNeighborsClassifier from sklearn.neighbors\nfrom sklearn.neighbors import KNeighborsClassifier \n\n# Setup arrays to store train and test accuracies\nneighbors = np.arange(1, 19)\ntrain_accuracy = np.empty(len(neighbors))\ntest_accuracy = np.empty(len(neighbors))\n\n# Loop over different values of k\nfor i, k in enumerate(neighbors):\n    # Setup a k-NN Classifier with k neighbors: knn\n    knn = KNeighborsClassifier(n_neighbors=k)\n\n    # Fit the classifier to the training data\n    knn.fit(X_train, y_train)\n    \n    #Compute accuracy on the training set\n    train_accuracy[i] = knn.score(X_train, y_train)\n\n    #Compute accuracy on the testing set\n    test_accuracy[i] = knn.score(X_test, y_test)\n\n# Generate plot\nplt.title('k-NN: Varying Number of Neighbors')\nplt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\nplt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\nplt.legend()\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This plot vary depending the features in the train dataframe **"},{"metadata":{"_uuid":"fde92524-540b-4aad-87fc-164b3214f3de","_cell_guid":"d1a4f598-1f49-4ad2-ba2e-529e412b8117","trusted":true},"cell_type":"markdown","source":"I will keep two of these models, with 6 neighbors and with 10 neighbors"},{"metadata":{"_uuid":"b853a474-2d3e-4d33-8b76-5d26665915b5","_cell_guid":"bac68e8d-e9f3-419a-ad8f-9852fbf74f40","trusted":true},"cell_type":"code","source":"# Import KNeighborsClassifier from sklearn.neighbors\nfrom sklearn.neighbors import KNeighborsClassifier \n\n# Create a k-NN classifier with 6 neighbors: knn\nknn_6 = KNeighborsClassifier(n_neighbors = 6)\n\n# Fit the classifier to the data\nknn_6.fit(scaled_features,y)\n\n# Predict the labels for the training data X\ny_pred_knn_6 = knn_6.predict(scaled_features_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2967a538-e0b1-4898-bdc0-7aa41ef43f36","_cell_guid":"c19e096c-162d-4f0d-9889-abe738cae92c","trusted":true},"cell_type":"code","source":"# Import KNeighborsClassifier from sklearn.neighbors\nfrom sklearn.neighbors import KNeighborsClassifier \n\n# Create a k-NN classifier with 6 neighbors: knn\nknn_10 = KNeighborsClassifier(n_neighbors = 10)\n\n# Fit the classifier to the data\nknn_10.fit(scaled_features,y)\n\n# Predict the labels for the training data X\ny_pred_knn_10 = knn_10.predict(scaled_features_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f70e6914-56e1-482b-a4b6-659724081da0","_cell_guid":"0db42fe8-95db-4d44-8a25-3ef376a65cae","trusted":true},"cell_type":"code","source":"#Upload the test file for KNN (scaled)\nresult_knn_6 = pd.read_csv(\"../input/gender_submission.csv\")\nresult_knn_6['Survived'] = y_pred_knn_6\nresult_knn_6.to_csv('Titanic_knn_5.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec1276d9-271d-4b80-a99b-3ecf91d2f2a6","_cell_guid":"1e92cd96-4223-4c26-b487-da70c04f2255","trusted":true},"cell_type":"code","source":"#Upload the test file for KNN (scaled)\nresult_knn_10 = pd.read_csv(\"../input/gender_submission.csv\")\nresult_knn_10['Survived'] = y_pred_knn_10\nresult_knn_10.to_csv('Titanic_knn_7.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"186e9687-4af5-4d0a-95bc-cb25f0907fae","_cell_guid":"07d0f227-28c6-4303-9914-22c1e153fe91","trusted":true},"cell_type":"markdown","source":"**Second model: Logistic Regression**"},{"metadata":{"_uuid":"eaeeb257-6a8f-49f7-8bdf-7888e86f0d01","_cell_guid":"4167134e-3875-45c8-ba68-b58141950228","trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(scaled_features,y)\ny_pred_logreg = logreg.predict(scaled_features_test)\ny_pred_logreg.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ba44e28-f66a-4bc1-8915-85b9b3d2fc13","_cell_guid":"d70dcdcb-6bd1-4706-8902-9457ddc281ea","trusted":true},"cell_type":"code","source":"#Upload the test file for Random Forest \nresult_logreg = pd.read_csv(\"../input/gender_submission.csv\")\nresult_logreg['Survived'] = y_pred_logreg\nresult_logreg.to_csv('Titanic_logreg.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e03e835-c3e7-45c0-9704-20fc687ddff6","_cell_guid":"238fadde-88d7-46cd-a7f9-9aa7695b92ad","trusted":true},"cell_type":"markdown","source":"**Third model : XGB Classifier**"},{"metadata":{"_uuid":"9c789aaa-37cd-414b-8bef-697128e9797f","_cell_guid":"dc120984-07f5-4eb5-bad8-780de5adbe16","trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost import XGBClassifier\n\nclf = xgb.XGBClassifier(n_estimators=250, random_state=4,bagging_fraction= 0.791787170136272, colsample_bytree= 0.7150126733821065,feature_fraction= 0.6929758008695552,gamma= 0.6716290491053838,learning_rate= 0.030240003246947006,max_depth= 2,min_child_samples= 5,num_leaves= 15,reg_alpha= 0.05822089056228967,reg_lambda= 0.14016232510869098,subsample= 0.9)\n\nclf.fit(scaled_features, y)\n\ny_pred_xgb= clf.predict(scaled_features_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be1917dc-76f4-40c1-b26f-4b51ef78d982","_cell_guid":"571bacd1-da6e-461e-a6e7-063b2ae01a39","trusted":true},"cell_type":"code","source":"#Upload the test file for Random Forest \nresult_xgb = pd.read_csv(\"../input/gender_submission.csv\")\nresult_xgb['Survived'] = y_pred_xgb\nresult_xgb.to_csv('Titanic_xgb.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f407858-cb54-41d3-bbaa-9117c7668809","_cell_guid":"21fe143c-e1fa-4c48-b0db-2a33a5e459fc","trusted":true},"cell_type":"markdown","source":"**4th Model RidgeClassifier**"},{"metadata":{"_uuid":"34a527b8-078b-4f31-a193-424f04d028fe","_cell_guid":"7edc10e6-3a98-415d-8b88-6834bb5536d1","trusted":true},"cell_type":"code","source":"rcf= RidgeClassifier()\nrcf.fit(scaled_features, y)\n\ny_pred_rcf= rcf.predict(scaled_features_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ada33672-749c-4d2d-9540-59c259a6e9e1","_cell_guid":"408ab339-1ff2-473f-945e-53005f112be9","trusted":true},"cell_type":"code","source":"#Upload the test file for  Ridge Classifier\nresult_rcf = pd.read_csv(\"../input/gender_submission.csv\")\nresult_rcf['Survived'] = y_pred_rcf\nresult_rcf.to_csv('Titanic_rcf.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ddcc7e39-cf55-44fd-8032-67ae38597bdc","_cell_guid":"5dabe144-94ea-4dc2-bc17-43487593cfe5","trusted":true},"cell_type":"markdown","source":"**5th model: Gradient Boosting Classifier**"},{"metadata":{"_uuid":"828e1aad-c58d-435b-8311-28d7848b8d67","_cell_guid":"3ef87f9d-2dcc-4cc8-8702-7c150c76af0d","trusted":true},"cell_type":"code","source":"gbc= GradientBoostingClassifier(n_estimators=100)\ngbc.fit(scaled_features, y)\ny_pred_gbc= gbc.predict(scaled_features_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5a25f80-4681-4f90-abf7-f5b06826c4a3","_cell_guid":"80279767-7fd1-465e-9d61-dc778dee3309","trusted":true},"cell_type":"code","source":"#Upload the test file for Bagging Ridge Classifie\nresult_gbc = pd.read_csv(\"../input/gender_submission.csv\")\nresult_gbc['Survived'] = y_pred_gbc\nresult_gbc.to_csv('Titanic_gbc.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"097f04d3-2a50-4190-806a-a6ba19552e3b","_cell_guid":"6a05bb5d-bca5-46a3-a48a-d9ced10eeed7","trusted":true},"cell_type":"markdown","source":"<a id=\"results\"></a> <br> \n**7. Results** \n"},{"metadata":{},"cell_type":"markdown","source":"We tested 4 options, first one training without any change in the features"},{"metadata":{},"cell_type":"markdown","source":"![](https://cdn-images-1.medium.com/max/1000/1*kZ9X3rMW9-Ohxd2UKx-y1w.png)"},{"metadata":{},"cell_type":"markdown","source":"the next try included all the features created in the first section:"},{"metadata":{},"cell_type":"markdown","source":"![](https://cdn-images-1.medium.com/max/1000/1*XbtLALV28nrdzBSG5IHm4g.png)"},{"metadata":{},"cell_type":"markdown","source":"Next, we include only with those features with entropy < 2, that is droping those columns that maybe add more noise than value"},{"metadata":{},"cell_type":"markdown","source":"![](https://cdn-images-1.medium.com/max/1000/1*Rn1oQJHrDRcDs3_oM6ZxbA.png)"},{"metadata":{},"cell_type":"markdown","source":"it seems that the global accuracy of all the models is increasing\nNext, we select only those features with entropy < 1,5 :"},{"metadata":{},"cell_type":"markdown","source":"![](https://cdn-images-1.medium.com/max/1000/1*ofXtRDzL5PtXvhIT0Qdk1A.png)"},{"metadata":{},"cell_type":"markdown","source":"It seems this feature combination give the better accuracy for all the algorithms"},{"metadata":{},"cell_type":"markdown","source":"Another point, for example, when trainning a KNN with several neighbords, the result depend on the features defined.\nWe plot the accuracy of KNN for several neighbors:"},{"metadata":{},"cell_type":"markdown","source":"![](https://cdn-images-1.medium.com/max/1000/1*xZwK315Z-wxV5EmqGI9y9Q.png)\n"},{"metadata":{"_uuid":"54213dac-a010-41b2-8527-f017107d12bf","_cell_guid":"678ef21c-4872-4eaa-a0ea-295e092ca75a","trusted":true},"cell_type":"markdown","source":"After submitting the diferent CSV I have obatined this results:\n- Using Random Forest: 0.73684\n- Using KNN with 6 neighboors:  **0.77990**\n- Using KNN with 10 neighboors: 0.77033\n- Using KGBClassifier:** 0.77990**\n- Using Ridge Classifier: 0.77511"},{"metadata":{"_uuid":"f2e3709e-3530-475d-9c69-5d8e3e87e450","_cell_guid":"cc1e630b-8160-4042-bbd5-513de08801e3","trusted":true},"cell_type":"markdown","source":" <font color=\"red\">If this kernel were useful for you, please <b>UPVOTE</b> the kernel ;)</font>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}